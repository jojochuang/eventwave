/* 
 * CondorHeartBeat.mac : part of the Mace toolkit for building distributed systems
 * 
 * Copyright (c) 2011, Wei-Chiu Chuang
 * All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 * 
 *    * Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    * Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *    * Neither the names of the contributors, nor their associated universities 
 *      or organizations may be used to endorse or promote products derived from
 *      this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
 * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * 
 * ----END-OF-LEGAL-STUFF---- */
#include "mlist.h"
#include <errno.h>
#include <fstream>
#include <sstream>
#include <signal.h>
// JOB_SPEC FILE is used to describe the mapping between context to nodes.
// i.e. what contexts are mapped to the same node.
// XXX: How to read file on Condor? Job may run on non-NFS systems
#define  DEFAULT_JOB_SPEC_FILENAME   "job.spec"
#define  DEFAULT_JOB_INPUT_FILENAME  "job.input"
service CondorHeartBeat;
provides HeartBeat;
trace = med;

constants{

  uint64_t JOIN_TIMEOUT = 10 *1000*1000; // How long to wait for the join to give up
  uint64_t HEARTBEAT_PERIOD = 5*1000*1000; // Period between heart beats
  uint64_t RELAUNCH_PERIOD = 5*60*1000*1000; // Period between launching new set of job requests

  uint64_t HEARTBEAT_TIMEOUT = HEARTBEAT_PERIOD * 2; // How long to wait for the heartbeat to declare lose connection.

  uint16_t MAX_JOB_SPEC_FILENAME_LEN    =  1024;

  uint32_t DEFAULT_MIN_NODES = 10;
  uint32_t DEFAULT_MAX_NODES = 20;
}

services {
    Transport tcp = TcpTransport();
}

states {
    PreJoin;
    Joining;
    Joined;
}

auto_types {

  NodeStatus __attribute((node())) {
    uint64_t timestamp;
    bool busy;
    uint32_t jobID;
    uint32_t hbProcessID;
    uint32_t uniProcessID;
  }

  JobInformation  {
    uint32_t jobID;
    mace::string serviceName; 
    MaceAddr vhead; 
    mace::string monitorName;
    ContextMapping mapping;
    mace::string inputName;
    mace::map< MaceAddr, mace::pair<uint32_t,uint32_t> > procID;
  }
}

typedefs {
    typedef mace::hash_map<MaceAddr, NodeStatus> NodeMap;
    typedef mace::list<MaceAddr> NodeList;
    typedef mace::map<MaceAddr, mace::set<mace::string> > ContextMapping;
}

constructor_parameters {
    uint32_t MIN_NODES = DEFAULT_MIN_NODES;
    uint32_t MAX_NODES = DEFAULT_MAX_NODES;
}

state_variables {
    MaceKey me;
    MaceKey master;
    timer join_timer; 
    timer heartbeat_timer __attribute((recur(HEARTBEAT_PERIOD)));
    timer relaunch_timer __attribute((recur(RELAUNCH_PERIOD)));
    NodeMap JoinedNodes; // used by master
    // NodeList peerNodes;
    uint32_t joinedNodeCount;
    uint32_t myId;

    // used by workers
    uint32_t jobpid;

    // used by master
    mace::map<uint32_t, JobInformation> JobStatus;
    uint32_t jobCount;
}

messages {
    Join { uint32_t pid; }
    JoinReply {uint32_t id; }

    HeartBeat {/*NodeList nodes;*/ }
    HeartBeatReply { }
    NotifySignal { int signum; }

    UpdateTotalNodes{ NodeList  nlist; }
    PeerCommunication{ }
    ReportRefusedConnection{ MaceKey from ; MaceKey to;}

    SpawnProcess{ mace::string serviceName; MaceAddr vhead; mace::string monitorName; ContextMapping mapping; mace::string snapshot; mace::string input; MaceKey vnode; }
    SpawnProcessResponse{ uint32_t unitapp_pid; }
    ReportJobMigration{ mace::string snapshot; }

    UpdateContextMapping{MaceAddr oldNode; mace::map< MaceAddr, mace::set< mace::string > > mapping; }
    UpdateVirtualNodes{ mace::map<uint32_t, MaceAddr> vnodes;  }

    RemoteTerminate{uint64_t migrate; }
    RequestMigrateContext{mace::string contextId; MaceAddr destNode; bool isRoot;}

    SplitContext{ MaceAddr dest; mace::string subtreeRootContext; bool isTree; }
    UpdateNodePerformance { }
}

transitions {
  downcall (state == init) maceInit() { state = PreJoin;
    // For bootstrapper, this call initiates the waiting of the coming nodes,
    // For other nodes, this call initiates a Join message to the bootstraper
    // after this call, a heart beat message is sent periodically to make sure
    // the connection is normal.
      std::string bootstrapper_node = params::get<std::string>("MACE_AUTO_BOOTSTRAP_PEERS");
      master = MaceKey(ipv4, bootstrapper_node);
      me = downcall_localAddress();

      if( master == me ){
          state = Joined;
          joinedNodeCount = 1;
          jobCount = 0;
          myId = 0;
          heartbeat_timer.reschedule( HEARTBEAT_PERIOD );
          if( params::get<bool>("norelaunch",true) == false ){
              return;
          }
          relaunch_timer.reschedule( RELAUNCH_PERIOD );
          relaunch(MAX_NODES); // launch MAX_NODES jobs initially
      }else{
          state = Joining;
          downcall_route( master, Join(getpid() ) );
          join_timer.reschedule( JOIN_TIMEOUT );

          jobpid = 0;
      }

  }
  downcall maceExit() {
  }
  downcall (state != init) maceExit() { }

    // the process waits for the console input, the input initiates the start of the service
    // this call should only be made by the membership service server.

  downcall  startService(const std::string& specFileName,const std::string& inputFileName) { 
    // parse the job specification file
    ContextMapping mapping;
    mace::string serviceName;
    mace::list< mace::set<mace::string> > spec;
    mace::string monitorName;
    mace::string input;
    
    if( ! parseJobSpec( spec, specFileName, serviceName, monitorName ) ){
        return;
    }
    if( inputFileName.size() > 0 ){
        if( ! parseJobInput( input, inputFileName ) ){
            return;
        }
    }
    // pick appropriate number of available nodes from the pool. designate one of which as the head
    
    mace::list<MaceAddr> freeNodes;
    findUnusedNodes(freeNodes, spec.size()+1);// one extra node for head

    if( freeNodes.size() < spec.size() + 1 ){ 
        maceout<<"not enough free nodes"<<Log::endl;
        return;
    }
    // map contexts to nodes
    mace::list< mace::set<mace::string> >::iterator specIt=spec.begin();
    mace::list<MaceAddr>::iterator nodeIt;
    nodeIt=freeNodes.begin();
    nodeIt++;
    MaceAddr globalNode;
    for( ; specIt != spec.end(); specIt++,nodeIt++){
        JoinedNodes[ *nodeIt ].busy = true;
        JoinedNodes[ *nodeIt ].jobID = jobCount;
        
        MaceAddr unitapp = hbToUni( *nodeIt );// (ipv4,addr.local.addr, addr.local.port-10000 );
        mapping[ unitapp ] = *specIt;

        // scan spec. 
        if( specIt->find("") != specIt->end() ){
            maceout<<"found global context is associated with "<< *nodeIt<<Log::endl;
            globalNode = *nodeIt;
        }

    }
    // update JobStatus  (head node)
    MaceAddr head = hbToUni( *( freeNodes.begin() ) ); //(ipv4,freeNodes.begin()->getMaceAddr().local.addr, freeNodes.begin()->getMaceAddr().local.port-10000 );
    JoinedNodes[ *(freeNodes.begin()) ].busy = true;
    JoinedNodes[ *(freeNodes.begin()) ].jobID = jobCount;
    // chuangw: i don't know why i need to make every parmeter const....
    const ContextMapping const_mapping = mapping;
    const mace::string const_serviceName = serviceName;
    const mace::string const_monitorName = monitorName;
    const mace::string const_inputName = inputFileName;
    JobInformation ji;
    ji.jobID = jobCount;
    ji.serviceName = serviceName;
    ji.vhead = head;
    ji.monitorName = monitorName;
    ji.mapping = mapping;
    ji.inputName = inputFileName;
    for(mace::list<MaceAddr>::iterator nit= freeNodes.begin(); nit != freeNodes.end(); nit++ ){
        ji.procID[ *nit ].first = JoinedNodes[ *nit ].hbProcessID;
    }
    JobStatus[ jobCount ] = ji;

    // send SpawnProcess message to the picked nodes
    /// FIXME: bug, all free node are used...
    mace::list<MaceAddr>::iterator it=freeNodes.begin();
    // spawn process to head first. wait sometime for the head to start up
    MaceKey destNode( ipv4, *it );
    MaceKey vNode( mace::vnode, ji.jobID );
    downcall_route( destNode, SpawnProcess( serviceName, head, monitorName, mapping, mace::string(""),mace::string(""), vNode ));
    SysUtil::sleepm(100);
    it++;
    for(;  it!=freeNodes.end(); it++ ){
        MaceKey destNode( ipv4, *it );
        if( *it == globalNode )
            downcall_route( destNode, SpawnProcess( serviceName, head, monitorName, mapping, mace::string(""),input, vNode ));
        else
            downcall_route( destNode, SpawnProcess( serviceName, head, monitorName, mapping, mace::string(""),mace::string(""), vNode ));
    }
    
    jobCount++;
  }
  downcall reportMigration(mace::string& snapshot){
    downcall_route( master, ReportJobMigration(snapshot) );
 
  }
  downcall showNodeStatus(){
    std::cout<<" Node Status"<<std::endl;
    std::cout<<"==========================================="<<std::endl;
    std::cout<<" Total joined number of nodes: "<< JoinedNodes.size() << std::endl;
    uint32_t freeNodes=0;
    NodeMap::iterator nodeIt;
    int nodeIndex=0; 
    for(nodeIt=JoinedNodes.begin(); nodeIt!=JoinedNodes.end(); nodeIt++,nodeIndex++){
        std::cout<<"["<<nodeIndex<<"]"<< nodeIt->first;
        if( nodeIt->second.busy )
            std::cout<< " busy: jobid="<<nodeIt->second.jobID <<std::endl;
        else{
            std::cout<< " free"<<std::endl;
            freeNodes ++;
        }
    }
    std::cout<<"==========================================="<<std::endl;
    std::cout<<" Free Nodes Number: "<< freeNodes<< std::endl;
  }
  downcall terminateRemoteAll(){
    NodeMap::iterator nodeIt;
    for(nodeIt=JoinedNodes.begin(); nodeIt!=JoinedNodes.end(); nodeIt++){
        MaceKey destNode( ipv4, nodeIt->first );
        downcall_route( destNode, RemoteTerminate(false) );
    }
    std::cout<<"message sent to remote nodes"<<std::endl;
  }
  downcall terminateRemote(const mace::list< MaceAddr >& migratedNodes, bool migrate){
    mace::list<MaceAddr>::const_iterator nodeIt;
    for(nodeIt=migratedNodes.begin(); nodeIt!=migratedNodes.end(); nodeIt++){
        if( JoinedNodes.find( *nodeIt ) == JoinedNodes.end() ){
            std::cout<<"the node does not exist"<<std::endl;
        }else{
            std::cout<<"sending terminate request to node "<< *nodeIt<<std::endl;
            const MaceKey destNode( ipv4, *nodeIt );
            downcall_route( destNode , RemoteTerminate(migrate) );
        }
    }
    std::cout<<"message sent to remote nodes"<<std::endl;
  }
  downcall terminateRemote(uint32_t nodes, bool migrate){
    // pick non-head nodes, and non-global context. create a head node set
    mace::set< MaceAddr > headNodes;
    for( mace::map<uint32_t, JobInformation>::iterator jit=JobStatus.begin(); jit!=JobStatus.end(); jit++){
        headNodes.insert( jit->second.vhead );
    }

    uint32_t migrationRequests = 0;
    NodeMap::iterator nodeIt = JoinedNodes.begin();
    while( migrationRequests < nodes && nodeIt != JoinedNodes.end() ){
        //MaceAddr heartbeatAddr = nodeIt->first.getMaceAddr();
        MaceAddr unitapp =  hbToUni( nodeIt->first ); //( ipv4, heartbeatAddr.local.addr, heartbeatAddr.local.port-10000 );
        // choose this node if it has been assigned a job and it's not a head
        // XXX: check to make sure this node is not assigned global context.
        if( headNodes.find( unitapp ) == headNodes.end() && nodeIt->second.busy == true ){
            const MaceKey destNode( ipv4, nodeIt->first );
            downcall_route( destNode, RemoteTerminate(migrate) );
            std::cout<<"sending terminate request to node "<< nodeIt->first <<std::endl;
            migrationRequests ++;
        }
        nodeIt++;
    }

    std::cout<<"message sent to a total of "<< migrationRequests<<" remote nodes"<<std::endl;
  }
  downcall migrateContext(const uint32_t jobID, const std::string& contextID, const bool isRoot){
    JobInformation& job = JobStatus[ jobID ];
    // find the physical node where the context is currently located.
    MaceAddr origNode = SockUtil::NULL_MACEADDR;
    // update mapping
    ContextMapping::iterator cmIt = job.mapping.end();
    for( cmIt = job.mapping.begin(); cmIt!=job.mapping.end(); cmIt++ ){
        if( cmIt->second.find( contextID ) != cmIt->second.end() ){
            origNode = cmIt->first;
        }
    }
    if( origNode == SockUtil::NULL_MACEADDR){
        // can't find the node of the context found!
        maceerr<<"Can't find the context!"<<Log::endl;
        return;
    }
    // 1: start a new node. 
    mace::list<MaceAddr> freeNodes;
    findUnusedNodes(freeNodes, 1);
    if( freeNodes.empty() ){
        // no free nodes
        maceerr<<"No free nodes available."<<Log::endl;
        return;
    }
    const MaceAddr& pickedAddr = *( freeNodes.begin() );
    const MaceKey destNode(ipv4, pickedAddr  );
    MaceAddr uniNode = hbToUni(pickedAddr);
    markNodeUsed( JoinedNodes[ pickedAddr  ], jobID ); // set the node as used.

    if( isRoot ){
        for( mace::set< mace::string >::iterator mapIt = job.mapping[origNode].begin(); mapIt != job.mapping[origNode].end(); mapIt++ ){
            if( contextID.compare(0, contextID.size(), *mapIt) == 0 ){
                job.mapping[ origNode ].erase( *mapIt );
                job.mapping[ uniNode ].insert( *mapIt );
            }
        }
    }else{
        job.mapping[ origNode ].erase( contextID );
        job.mapping[ uniNode ].insert( contextID );
    }
    MaceKey vNode( mace::vnode, jobID );
    // tell the node to start a new service, but stay dormant, Do nothing
    downcall_route( destNode, SpawnProcess( job.serviceName, job.vhead, job.monitorName, job.mapping, "" /*snapshot*/,"" /*input*/, vNode ));
    // send request message to head
    MaceKey hbHead( ipv4, uniToHb(job.vhead) );
    downcall_route(  hbHead, RequestMigrateContext( contextID, uniNode, isRoot ) );
    // would need to update the context mapping at the job scheduler.
  }
  downcall splitNodeContext(const uint32_t jobID, const MaceAddr& nodeKey){
    //JobInformation& job = JobStatus[ jobID ];
    //mace::list<mace::string>& contexts = job.mapping[ nodeKey ];

    maceout<<"TODO: need to figure out how to split contexts into two"<<Log::endl;
  }
  downcall void updateNodePerformance(){
    downcall_route( master, UpdateNodePerformance( )  );
  }
  downcall bool getNodeInfo(const uint32_t jobid,const uint32_t nodeid, mace::string& nodeHostName, uint32_t& node_unixpid, uint32_t& uniapp_unixpid){

    if( nodeid == 0 ){
        MaceAddr heartbeatHeadAddr = uniToHb(JobStatus[ jobid ].vhead);
        const MaceKey heartbeatHeadApp( ipv4, heartbeatHeadAddr );
        node_unixpid = JobStatus[ jobid ].procID[ heartbeatHeadAddr ].first;
        uniapp_unixpid = JobStatus[ jobid ].procID[ heartbeatHeadAddr ].second;
        nodeHostName = Util::getHostname(  heartbeatHeadApp );
    }else{
        if( JobStatus[jobid].mapping.size()+1 <= nodeid ){
            std::cout<<"node id out of range!"<<std::endl;
            return false;
        }
        uint32_t nodeIndex=1;
        ContextMapping::iterator nodeIt;
        for( nodeIt = JobStatus[jobid].mapping.begin(); 
            nodeIt != JobStatus[jobid].mapping.begin(), nodeIndex != nodeid ; nodeIt ++,nodeIndex++ ){ }

        MaceAddr heartbeatAddr = uniToHb( nodeIt->first );
        const MaceKey heartbeatApp( ipv4, heartbeatAddr );
        node_unixpid = JobStatus[ jobid ].procID[ heartbeatAddr ].first;
        uniapp_unixpid = JobStatus[ jobid ].procID[ heartbeatAddr ].second;
        nodeHostName = Util::getHostname( heartbeatApp );
    }
    return true;
  }
 
  downcall showJobStatus(){
    int servIndex = 0;
    mace::map<uint32_t, JobInformation>::iterator servIt;
    std::cout<<" Job Status"<<std::endl;
    std::cout<<"==========================================="<<std::endl;
    std::cout<<" Total joined number of nodes: "<< JoinedNodes.size() << std::endl;
    uint32_t freeNodes=0;
    for(servIt= JobStatus.begin(); servIt != JobStatus.end(); servIt++, servIndex++){
        std::cout<<">>("<<servIndex<<")"<< servIt->second.serviceName <<" jobid:"<< servIt->second.jobID <<" no. of nodes:"<< servIt->second.mapping.size()<<" vhead: "<<servIt->second.vhead <<std::endl;
        int nodeIndex=0; 
        std::cout<<"   ["<<nodeIndex<<"]"<< servIt->second.vhead;
        
        MaceAddr heartbeatHeadApp = uniToHb(servIt->second.vhead);
        if( JoinedNodes.find( heartbeatHeadApp ) == JoinedNodes.end() ){
            std::cout<<"[left   ](head)";
        }else{
            std::cout<<"[running](head)";
        }
        std::cout<<" unixpid: "<< servIt->second.procID[ heartbeatHeadApp ].second <<std::endl;

        nodeIndex++;
        ContextMapping::iterator nodeIt= servIt->second.mapping.begin();
        for(; nodeIt != servIt->second.mapping.end(); nodeIt++, nodeIndex++){
            std::cout<<"   ["<<nodeIndex<<"]"<< nodeIt->first <<" : ";

            MaceAddr heartbeatApp = uniToHb( nodeIt->first ); 

            if( JoinedNodes.find( heartbeatApp ) == JoinedNodes.end() ){
                std::cout<<"[left   ]";
            }else{
                std::cout<<"[running]";
            }
            for( mace::set<mace::string>::iterator contextIt= nodeIt->second.begin(); contextIt!=nodeIt->second.end(); contextIt++){
                if( *contextIt == "" )
                    std::cout<< "(global)" <<",";
                else
                    std::cout<< *contextIt <<",";
            }
            std::cout<<" unixpid: "<< servIt->second.procID[ heartbeatApp ].second <<std::endl;
            std::cout<<std::endl;
        }
        std::cout<<"-------------------------------------------"<<std::endl;
        freeNodes += ( servIt->second.mapping.size()+1);
    }
    freeNodes = JoinedNodes.size() - freeNodes;
    std::cout<<"==========================================="<<std::endl;
    std::cout<<" Free Nodes Number: "<< freeNodes<< std::endl;
  }

  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const Join& msg) {
    // make sure i'm the bootstrapper....
    JoinedNodes[ from.getMaceAddr() ].timestamp = curtime;
    JoinedNodes[ from.getMaceAddr() ].hbProcessID = msg.pid;
    downcall_route( from, JoinReply(joinedNodeCount) );
    joinedNodeCount++;
  }
  upcall (state == Joining) deliver(const MaceKey& from, const MaceKey& dest, const NotifySignal& msg) {
    maceout<<"a peer node "<< dest << "receives a signal "<< msg.signum <<Log::endl;
  }

  upcall (state == Joining) deliver(const MaceKey& from, const MaceKey& dest, const JoinReply& msg) {
    // connection confirmed
    myId = msg.id;
    maceout<<"I am assigned id "<<myId<<Log::endl;
    state = Joined;
  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const ReportRefusedConnection& msg) { 
    // only master is expected to receive this message

  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const HeartBeat& msg) { 
    // send back a reply
    // test: ignore msg.nodelist
    downcall_route( from, HeartBeatReply() );
  }  
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const HeartBeatReply& msg) { 
    // update the timestamp of the node connection status
    JoinedNodes[from.getMaceAddr() ].timestamp = curtime;
  }  
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const UpdateTotalNodes& msg) { 
  }  
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const PeerCommunication& msg) { 
  }  

  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const SpawnProcess& msg) { 
/* this upcall is called when the membership service server tells this node to use this node to spawn the service.

msg.serviceName : the service to execute.
msg.vhead : the server determines one of the node is the head.
msg.mapping : this is meaningful only for the head. To other nodes, this will be empty container
    typedef mace::map<MaceKey, mace::list<mace::string> > ContextMapping;
*/
    uint32_t unitapp_pid = upcall_spawnProcess(msg.serviceName, msg.vhead,  msg.monitorName,  msg.mapping, msg.snapshot, msg.input, myId, msg.vnode);

    downcall_route( from, SpawnProcessResponse( unitapp_pid ) );
     
  }  
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const SpawnProcessResponse& msg) { 
    // store the created unit_app pid
    JobStatus[ JoinedNodes[ from.getMaceAddr() ].jobID ].procID[ from.getMaceAddr() ].second = msg.unitapp_pid;
  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const UpdateVirtualNodes& msg) { 
    //UpdateVirtualNodes{ mace::map<MaceKey, MaceAddr> vnodes;  }
    //TODO: worker node receives update message, call upper handler to notify the unit_app 
    // only the head node should be aware of this..
    upcall_updateVirtualNodes( msg.vnodes );
  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const UpdateContextMapping& msg) { 
    // write to context file
    mace::string buf;
    std::cout<<"in deliver(UpdateContextMapping)"<<std::endl;
    mace::serialize( buf, &(msg.mapping) );
    std::cout<<"serializing new mapping"<<std::endl;

    /*std::fstream fp(contextfile.c_str(), std::fstream::out);
    std::cout<<"writing to file "<< contextfile<<std::endl;
    mace::string serialized_oldNode;
    mace::serialize(serialized_oldNode, &(msg.oldNode) );
    std::cout<<"serializing old node macekey"<<std::endl;
    fp.write(serialized_oldNode.data() , serialized_oldNode.size() );
    fp.write(buf.data() , buf.size() );
    fp.close();*/
    std::cout<<"finished writing update context file"<<std::endl;
    // TODO: send a signal to child unit_app process.
    
    kill( jobpid, SIGUSR1 );
  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const ReportJobMigration& msg) { 
    // master receives this message when Condor sends SIGTERM to one of the job, telling it to terminate.
    // the snapshot was taken, and we need to decide which node to resume snapshot again
    

    // update JoinedNodes and update JobStatus
    // assuming head node does not move.
    std::cout<<"Node "<<from<<" was vacated. Finding new node to migrate snapshot"<<std::endl;

    if( JoinedNodes.find( from.getMaceAddr() ) == JoinedNodes.end() ){
        std::cout<<"from ("<< from <<"), migrated state/context snapshot is from a node I don't know. (not in JoinedNodes)"<<std::endl;
    }
    uint32_t jobID = JoinedNodes[ from.getMaceAddr() ].jobID;
    JobInformation& job = JobStatus[ jobID ];
    
    MaceAddr old_unitapp = hbToUni(from.getMaceAddr() );//   (ipv4, old_hbaddr.local.addr, old_hbaddr.local.port-10000);
    if( job.mapping.find( old_unitapp ) == job.mapping.end() ){
        std::cerr<<"the node's job id is "<< jobID << ", but can't find the node in this job. (head?)"<<std::endl;
        std::cerr<<"something's wrong! the migrated node was not in JobStatus. Ignore."<<std::endl;
        return;
    }
    std::cout<<"old_unitapp="<<old_unitapp<<std::endl;
    if( job.mapping.find(old_unitapp) == job.mapping.end() ){
        std::cerr<<" job.mapping[old_unitapp] doesn't exist."<<std::endl;
        return;
    }
    mace::set<mace::string>& updateMapping = job.mapping[old_unitapp];

    // search in JoinedNodes, find not busy one.
    MaceAddr NewNodeAddr = SockUtil::NULL_MACEADDR;
    for( NodeMap::iterator i=JoinedNodes.begin(); i!= JoinedNodes.end(); i++){
        if( i->second.busy ){
            //maceout<<i->first<<" is busy"<<Log::endl;
        }else{
            //maceout<<i->first<<" is free"<<Log::endl;
            NewNodeAddr = i->first;
            i->second.busy = true;
            i->second.jobID = JoinedNodes[from.getMaceAddr()].jobID;
            break;
        }
    }
    if( NewNodeAddr == SockUtil::NULL_MACEADDR ){
        std::cout<<"Can't find free node!!!!"<<std::endl;
        return;
    }
    std::cout<<"found a free node ("<< NewNodeAddr <<" ) to migrate."<<std::endl;
    // update context/node mapping

    MaceAddr new_unitapp = hbToUni(NewNodeAddr); //(ipv4,addr.local.addr, addr.local.port-10000 );

    job.mapping[ new_unitapp ] = updateMapping;

    job.mapping.erase( old_unitapp );

    std::cout<<"Found a free node "<<NewNodeAddr<<" to migrate. Transfer snapshot and update context mapping."<<std::endl;
    // determine if the old node has global context
    bool hasGlobalContext = false;
    // FIXME: mapping not in printable format?
    std::cout<<"Affected mapping:"<<std::endl;
    std::cout<<job.mapping[new_unitapp] << std::endl;
    if( job.mapping[new_unitapp].find("") != job.mapping[new_unitapp].end() ){
            hasGlobalContext = true;
    }
    mace::string input;
    if( hasGlobalContext ){ // FIXME
        std::cout<<"Migrating the global context node"<<std::endl;
        if( !parseJobInput( input, job.inputName ) ){
            maceout<<"parseJobInput failed to read input. Ignore this operation"<<Log::endl;
            return;
        }
    }else{
        std::cout<<"doesn't have global context"<<std::endl;
    }
    std::cout<< "service:" << job.serviceName <<std::endl;
    std::cout<< "head:   " << job.vhead <<std::endl;
    std::cout<< "monitor:" << job.monitorName <<std::endl;
    std::cout<< "mapping:" << job.mapping <<std::endl;
    std::cout<< "snapshot size: "<< boost::lexical_cast<std::string>(msg.snapshot.size()) <<std::endl;
    const MaceKey newNode( ipv4, NewNodeAddr );
    const MaceKey vNode( mace::vnode, job.jobID );
    downcall_route( newNode, SpawnProcess( job.serviceName, job.vhead, job.monitorName, job.mapping, msg.snapshot,input, vNode  ));

    // also, need to inform other nodes in the same job about the updat of context mapping
    mace::map<MaceAddr, mace::set<mace::string> > newMapping;
    newMapping[ new_unitapp ] =  job.mapping[new_unitapp];
    for( ContextMapping::iterator cmIt = job.mapping.begin(); cmIt != job.mapping.end(); cmIt++){
        if( cmIt->first == new_unitapp ) continue;

        MaceAddr hbPeerAddr = uniToHb(cmIt->first);   //(ipv4,addr.local.addr, addr.local.port+10000 );

        std::cout<<"informing node "<< hbPeerAddr << " about the update."<<std::endl;
        
        const MaceKey hbPeer( ipv4, hbPeerAddr );
        downcall_route( hbPeer, UpdateContextMapping( old_unitapp,newMapping  ));
    }
    // FIXME: need to notify the head as well.
    //addr = job.vhead.getMaceAddr();
    MaceKey hbhead( ipv4, uniToHb(job.vhead) );

    std::cout<<"informing node "<< hbhead << " about the update."<<std::endl;
    
    downcall_route( hbhead, UpdateContextMapping( old_unitapp,newMapping  ));

  }
  
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const SplitContext& msg ) {
  //{ MaceKey dest,mace::string subtreeRootContext; }
    //upcall_requestContextSplit
  }
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const UpdateNodePerformance& msg ) { 
    // TODO: received by job scheduler.
    // the job scheduler determines the migration policy after gathering node data
  }

  // received by the worker of the head node
  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const RequestMigrateContext& msg) {
    upcall_requestMigrateContext( msg.contextId, msg.destNode, msg.isRoot );
  }

  upcall (state == Joined) deliver(const MaceKey& from, const MaceKey& dest, const RemoteTerminate& msg) {
    // when RemoteTerminate message is sent from job manager, terminate the child process and myself.
    // child will respond with SIGUSR2 when its snapshot is done. Ignore snapshot and terminate.
    std::cout<<"Received request to terminate from master"<<std::endl;
    if( jobpid > 0 ){
        if( msg.migrate ){ // kill without migration
            std::cout<<"terminate for migrate"<<std::endl;
            upcall_ignoreSnapshot(false);
        }else{
            std::cout<<"terminate without snapshot"<<std::endl;
            upcall_ignoreSnapshot(true);
        }
        std::cout<<"kill child (unit_app) process pid "<< jobpid <<std::endl;
        kill( jobpid, SIGTERM );
    }else{ // no job is running. kill myself and leave
        std::cout<<"Not running anything. simply leave"<<std::endl;
        kill( getpid(), SIGTERM );
    }
  }

  upcall  messageError(const MaceKey& dest, TransportError::type error_code, const Join& msg, registration_uid_t regId) {
    maceout<<"Join failed dest:"<<dest<<"error code: "<< error_code<<"original msg:"<<msg<<Log::endl;
  }
  upcall  messageError(const MaceKey& dest, TransportError::type error_code, const JoinReply& msg, registration_uid_t regId) {
    maceout<<"JoinReply failed dest:"<<dest<<"error code: "<< error_code<<"original msg:"<<msg<<Log::endl;
  }
  upcall  messageError(const MaceKey& dest, TransportError::type error_code, const HeartBeat& msg, registration_uid_t regId) {
    maceout<<"HeartBeat failed dest:"<<dest<<"error code: "<< error_code<<"original msg:"<<msg<<Log::endl;
  }
  upcall  messageError(const MaceKey& dest, TransportError::type error_code, const HeartBeatReply& msg, registration_uid_t regId) {
    maceout<<"HeartBeatReply failed dest:"<<dest<<"error code: "<< error_code<<"original msg:"<<msg<<Log::endl;
  }

  upcall  messageError(const MaceKey& dest, TransportError::type error_code, const PeerCommunication& msg, registration_uid_t regId) {
    maceout<<"PeerCommunication failed dest:"<<dest<<"error code: "<< error_code<<"original msg:"<<msg<<Log::endl;
  }

  upcall error(const MaceKey& nodeId, TransportError::type error_code, const std::string& m, registration_uid_t registrationUid) {

    //if( me != master )
    //    downcall_route( master, ReportRefusedConnection(me, nodeId) );
  }
  scheduler (state == Joining) join_timer() {
    // join message expired.

    // can't reach the master
  }
  scheduler  relaunch_timer (){
    if( params::get<bool>("norelaunch",true) == false ){
        return;
    }

    // if number of responsive nodes is below MIN_NODES, relaunch 
    // MAX_NODES - MIN_NODES nodes.
    //if( JoinedNodes.size() < params::get<uint32_t>("MIN_NODES") )
    //relaunch(params::get<uint32_t>("MAX_NODES") - JoinedNodes.size());
    int idleJobs= checkJobStatus();
    if( idleJobs + JoinedNodes.size() < MIN_NODES){
        relaunch( MIN_NODES - idleJobs - JoinedNodes.size() );
    }
  }
  scheduler  heartbeat_timer (){
    // check which peer has not responded yet. If so, remove it.
    NodeList tobeDeleted;
    NodeList aliveNodes;
    for( NodeMap::iterator i=JoinedNodes.begin(); i!= JoinedNodes.end(); i++){
        if( curtime - i->second.timestamp > HEARTBEAT_TIMEOUT ){
            tobeDeleted.push_back(i->first);
        }else{
            aliveNodes.push_back(i->first);
        }
    }
    // clear the nodes
    for( NodeList::iterator i=tobeDeleted.begin();i!=tobeDeleted.end();i++){
        JoinedNodes.erase( *i );
    }
    maceout<<"number of responsive nodes:"<< JoinedNodes.size() <<Log::endl;
    for( NodeMap::iterator i=JoinedNodes.begin(); i!= JoinedNodes.end(); i++){
        // send heartbeat
        const MaceKey joinedNode( ipv4, i->first );
        downcall_route( joinedNode, HeartBeat( /*aliveNodes*/  ) );
    }
  }
  downcall notifySignal(int signum){
      downcall_route( master, NotifySignal(signum) );
  }

}

routines {
    MaceAddr hbToUni( const MaceAddr& heartbeatApp ){
        MaceAddr uniApp = heartbeatApp;
        uniApp.local.port-=10000 ;
        return uniApp;
    }
    MaceAddr uniToHb( const MaceAddr& uniApp ){
        MaceAddr heartbeatApp = uniApp;
        heartbeatApp.local.port+=10000;
        return heartbeatApp;
    }
    void markNodeUsed( NodeStatus& node, const uint32_t jobID ){
        node.busy = true;
        node.jobID = jobID;
    }
    void findUnusedNodes(mace::list<MaceAddr>& freeNodes, uint16_t nodes){
        for( NodeMap::iterator nmIt=JoinedNodes.begin(); nmIt != JoinedNodes.end() && freeNodes.size() < nodes; nmIt ++){
            if( nmIt->second.busy == false ){
                freeNodes.add( nmIt->first );
            }
        }

    }
    bool parseJobInput( mace::string& input, const mace::string& inputFileName ){
        std::fstream tempFile;
        if( inputFileName.size() == 0 ){ 
            // open using default file name
            tempFile.open( DEFAULT_JOB_INPUT_FILENAME, std::fstream::in);
            maceout<<"input file name: "<<DEFAULT_JOB_INPUT_FILENAME<<Log::endl;
        }else{
            tempFile.open( inputFileName.c_str(), std::fstream::in);
            maceout<<"input file name: "<<inputFileName<<Log::endl;
        }
        if( ! tempFile.is_open() ){
            maceout<<"Can't open input file"<<inputFileName<<Log::endl;
            return false;
        }
        char *buf;
        int fileLen = 0;

        tempFile.seekg( 0, std::ios::end);
        fileLen = tempFile.tellg();
        tempFile.seekg( 0, std::ios::beg);

        maceout<<". file size: "<< fileLen <<Log::endl;
        

        buf = new char[ fileLen ];
        while( ! tempFile.eof() ){
            tempFile.read(buf, fileLen);
        }
        tempFile.close();
        input = mace::string( buf, fileLen );
        delete buf;

        return true;
    }

    bool parseJobSpec( mace::list< mace::set<mace::string> >& spec, const std::string& jobSpecFile, mace::string& serviceName, mace::string& monitorName ){
        std::fstream file;

        if( jobSpecFile.size() == 0 ){ 
            // open using default file name
            file.open( DEFAULT_JOB_SPEC_FILENAME, std::fstream::in);
        }else{
            file.open( jobSpecFile.c_str(), std::fstream::in);
        }
        if( ! file.is_open() ){
            return false;
        }
        char buf[MAX_JOB_SPEC_FILENAME_LEN];
        while( !file.eof() ){
            std::string label;
            mace::set<mace::string> contextlist;
            file.getline(buf, MAX_JOB_SPEC_FILENAME_LEN);

            std::stringstream ss( buf );
            ss>>label;

            if( label.compare("service:") == 0 ){
                ss>>serviceName;
                continue;
            }else if( label.compare("monitor:") == 0 ){
                ss>>monitorName;
                continue;
            }else if( label.compare("node:") != 0 )
                continue;

            std::string contextname;

            while( true ){
                ss>>contextname;
                if( ss.bad() || ss.fail() ){
                    break;
                }
                if( contextname.size() == 0 )
                    break;

                // special treatment for global context
                if( contextname == "global" )
                    contextname = "";

                contextlist.insert( contextname );

            }
            if( !contextlist.empty() ){
                spec.push_back( contextlist );
            }
        }

        file.close();

        return true;
    }
    void relaunch(uint32_t numberLaunchNodes){
        // target machines on BoilerGrid.
        std::string launchCallStr;
        if( params::containsKey("cloud") || (params::containsKey("pool") && params::get<std::string>("pool") == std::string("cloud") )  ){
            launchCallStr="ssh cloud02 ./runworker.sh " + boost::lexical_cast<std::string>(numberLaunchNodes) + "  &";
        }else if(params::containsKey("condor")|| (params::containsKey("pool") && params::get<std::string>("pool") == std::string("condor") )){
            launchCallStr="ssh condor-fe02.rcac ./createjobs.sh " + boost::lexical_cast<std::string>(numberLaunchNodes) + " &";
        }
        maceout<<"launching: " +launchCallStr<<Log::endl;
        system(launchCallStr.c_str());
    }
    int checkJobStatus(){
        if( params::containsKey("cloud") || params::get<mace::string>("pool","") == "cloud" ){
            return 0;
        }
        std::string launchCallStr="ssh condor-fe02.rcac \"condor_q|tail -n1\" | awk '{print $3}' ";
        FILE *fp = popen(launchCallStr.c_str(), "r");
        int idleJobs=-1;
        int status;
        if( fp == NULL ){

        }
        if( status == -1 ){

        }
        char bufResult[1024];
        fgets( bufResult, sizeof(bufResult), fp);
        status = pclose(fp);
        idleJobs = atoi( bufResult );

        return idleJobs;
    }
}


